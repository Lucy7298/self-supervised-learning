# @package _global_

defaults:
  - override /trainer: default.yaml
  - override /model: byol.yaml
  - override /transforms: simclr_default.yaml
  - override /callbacks: pretrain_callbacks.yaml 
  - override /train_dataset: null # will be overridden on command line
  - override /val_dataset: null # will be overridden on command line

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

#train_dataset: concat_datasets(['train_dataset/imagenette.yaml', subset_dataset('train_dataset/places.yaml', 1000)])

logger: 
  wandb: 
    group: byol_pretrain_dsets
    job_type: "pretrain"

model: 
  kwargs: 
    eval_interval: -1

trainer: 
  max_epochs: 1000
  precision: 32

num_workers: -1 # use 4 * number of GPUs
batch_size: 32