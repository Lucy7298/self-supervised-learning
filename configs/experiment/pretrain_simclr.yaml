# @package _global_

defaults:
  - override /trainer: default.yaml
  - override /model: simclr.yaml
  - override /transforms: simclr_default.yaml
  - override /callbacks: pretrain_callbacks.yaml 
  - override /train_dataset: null # will be overridden on command line
  - override /val_dataset: null # will be overridden on command line

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

logger: 
  wandb: 
    group: simclr_pretrain_dsets
    job_type: "pretrain"

trainer: 
  max_epochs: 1000
  precision: 32

model: 
  kwargs: 
    eval_interval: -1

num_workers: -1 # use 4 * number of GPUs
batch_size: 32